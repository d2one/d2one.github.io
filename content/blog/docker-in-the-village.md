+++
date = "2017-08-25T04:03:46-06:00"
draft = false
title = "Docker в деревне"
slug = "docker-in-the-village"

+++
Сегодня в мире возникает очень большое количество различных технологических решений. Часть их них остаетсч с нами на очень долгое время, часть уходит. Docker показал, что он в нашей жизни в серьез и надолго. Поэтому в сегодняшних реалиях его должен уметь использовать каждый уважающий себя разработчик. Обсуждая с коллегами будущее индустрии веб разработки, каждый наш разговор заканчивался возможностью использования Docker’a и тем, насколько он удобен. 

Почитав теорию, я принял решение познакомится с использованием докера в маленьком пет-проекте. На самом деле давно хотелось сделать что-то интересное и наконец начать писать блог. Как и все разработчики, я достаточно ленив. И вне не хотелось делать достаточно много действий, чтобы заморачиваться с выкладкой. Хотелось чтобы все мои заметки хранились централизованно и, желательно не в базе. Иначе все бы свелось к заворачиванию wordpress/joomla/drupal в контейнер рядом с базой. Хотелось ничего не верстать, использовать аналитику. Решение должно быть портируемо на разные хостинги без особого усложнения.  

Выделил особо важные пункты:

- использование docker 
- статичные файлы с текстами
- темы (чтобы ничего не верстать)
- легкость миграции между хостингами
- атоматический ssl для домена, желательно бесплатно и бесрочно

После изучения проблем, которые хотелось решить - я наткнулся на hugo. Статический генератор сайтов, который написан на go, котороый генерирует сайт очень быстро, имеет встроенный сервер, для просмотра вида статьи локально. У него огромное количество тем на любой вкус, в некоторых присутствует аналитика от гугла. И самое главное, он позволяет хранить все в статичных markdown файлах. Меня это в целом устроило и hugo попал в мой список инструментов. Он решит проблему хранения материалов. При добавлении материала в течении нескольких секунд он сможет перегенеровать весь сайт.

Хранить данные своих материалов я собрался на github в markwown. В идеально мире схема взаимодействия должна была выглядеть примерно так. Я делаю пуш на гитхаб - сайт перегенеруется и начинает отдаваться уже обновленные данные. 

Так как результатом работы hugo является набор html файлов - то их надо каким-то образом раздавать. Не могу припомнить лучший сервер для раздачи статичных файлов, чем nginx.
Таким образом в набор софвта попал nginx. 

Решение должно масштабироваться. Вдруг мой ресурс станет очень популярным - то тогда я мог бы достаточно просто иметь возможность увеличить отдачу контента. То есть получается, что я должен иметь поставить не 1 nginx,  а , например 10. 

Для того, чтобы hugo узнал о том, что был push в репозиторий со статьями на github, необходим был какой то механизм. Github поддерживает web-hooks. Поэтому необходимо в контейнер, в котором находится hugo, иметь возможность поймать определенный web-hook и запустить перегенерацию сайта hugo. Для этого я выбрал Hookdoo. Это демон написанный на go, который слушает определенный порт и при получении выполняет определенные команды.

Подумав над всеми требованиями, стало понятно что общая схема будет выглядеть так.
Имеется сервис с nginxом, у которого есть общий volume с сервисом, в котором запущен hugo с webhook’ом. Так же существую образы docker-gen с letsecrypt. При использовании letsencrypt, ssl сертификаты будет автоматически добавляться в nginx и так же они начнут использоваться.

Однако вариант с использованием nginx + doker-gen + letsencrypt не взлетел по нескольким причинам. Хотелось использовать docker stack для деплоя сервисов, а не конкретных контейнеров. Соответственно docker-compose.yml становился > 3-й версии. А 3-я версия частично не поддерживает ключи конфигурации из 2-й. Можно было бы использовать docker-compose, но, насколько я понял, он подойдет для локальной разработки. В случае с использованием nginx - отдельно, docker-gen и letsencrypt в разных контейнерах, то контейнеру c docker-gen необходимо было присвоить label. А это не возможно в реалиях docker stack. После попыток пары вечеров безуспешных попыток завести данную схему, подумал, что можно на входе поставить не nginx, а прокси, которая сама умеет получать сертификаты от letsencrypt.
Этим прокси оказался traefic. Этот прокси умеет получать ssl сертификаты и проксировать трафик внутрь docker’a по разным условиям. Начиная от передаваемых заголовков, кончая именем хоста. 

По итогу имеем теоретическую схемы работы.

Имеем сервер, на котором инициализирован swarm и имеется внутренняя overlay сеть.
Есть traefic,  у него открыты 80 и 443 порты для обработки соединений. Он проксирует запросы во внутреннюю сеть. Внутри сети стоит nginx, и раздает статику, которую генерирует контейнер с hugo и web-hook’ом.

Теоретическая часть готова, переходим к практике. Чтобы проверить все гипотезы, понадобится сервер. Я взял дроплет у DigitalOcean за 5 баксов в месяц. 
По железу:

- 1 cpu
- 512mb оперативки
- 20GB ssd дисков

Так же в дроплете уже установлен docker 17.06, который поддерживает multi-staging.
Возникла необходимость в приватном registry для хранения образов. Можно все сделать на gitlub’е. Я же просто работал с репозиториями и собирал образ из них в самом дроплете. Если у вас >1 дроплета, то тогда есть необходимость в registry.

Очень помогло то, что в docker 17.06 появился multi-staging. Это хорошо тем, что можно для сборки необходимого софта использовать 1 контейнер, а потом скопировать полученные артефакты сборки в новый образ. Например для сборки образа с hugo и webhook - 

    FROM golang:1.8-alpine
    RUN go get -v github.com/adnanh/webhook
    RUN go get -v github.com/spf13/hugo
    FROM alpine
    COPY --from=0 /go/bin/webhook /usr/local/bin/webhook
    COPY --from=0 /go/bin/hugo /usr/local/bin/hugo

Образы traefic и nginx взял оригинальные. По факту мне оставалось примонтировать volumes из контейнера с hugo к контейнеру с nginx.

      image: hugo
      volumes:
        - $PWD/volumes/nginx/html/:/usr/share/nginx/html/

и в Nginx

      image: nginx
      volumes:
        - $PWD/volumes/nginx/html/:/usr/share/nginx/html/

Так же необходимо было сделать описать хуки в образе с hugo.  

    [
      {
        "id": "redeploy",
        "execute-command": "/run.sh",
        "pass-arguments-to-command": [
            { "source": "string", "name": "webhook" }
        ]
      }
    ]

Чтобы веб-хук сработал, необходимо его спроксировать через traefic. У контейнера с traefic открыт 9000 порт, который слушает вебхук. Для этого в docker-compose.yml необходимо прописать правила проксирования в данный контейнер.

    image: hugo
    deploy:
      mode: replicated
      replicas: 1
      labels:
        - "traefik.port=9000"
        - "traefik.docker.network=traefik-net"
        - "traefik.backend=hugo"
        - "traefik.frontend.rule=PathPrefix:/hooks/"
        - "traefik.backend.loadbalancer.method=drr"
        - "traefik.backend.loadbalancer.swarm=true"

Это значит, что при обращении по урлу hooks этот запрос будет спроксирован в контейнер с hugo на 9000 порт. В качестве load balancer будет выступать сам swarm.
 
В веб-морде trarfic’а можно посмотреть, что получилось по факту:

![](https://d2one.ru/images/docker-in-the-village/traefic-backend.png)


Весь исходный код можно посмотреть по ссылке 
Сейчас у меня есть блог, который работает сам по себе. Сам обновляет сертификаты, у нем легко изменить полностью все оформление, лишь поправив конфиг. Так же все материалы можно переиспользовать и, например, сделать копию сайта через github pages.


Какие вывод можно сделать?

- Docker - это интересно
- Из-за активного развития платформы и экосистемы все мануалы и howto очень быстро устаревают. Приходится разбираться самому, и пытаться понять, а что же ты хочешь получить.
- Важно чтобы рядом были люди. которых можно было бы спросить о некоторых нюансах и best practise. Это эконоит кучу времени.

